{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1.\n",
    "\n",
    "Обязательная часть\n",
    "Будем парсить страницу со свежеми новостям на habr.com/ru/all/.\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "\n",
    "Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы).\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <дата> - <заголовок> - <ссылка>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительная часть (необязательная)\n",
    "Улучшить скрипт так, чтобы он анализировал не только preview-информацию статьи, но и весь текст статьи целиком.\n",
    "\n",
    "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.\n",
    "\n",
    "Итоговый датафрейм формировать со столбцами: <дата> - <заголовок> - <ссылка> - <текст статьи>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS = ['python', 'парсинг']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_in_harb_posts(keys):\n",
    "    '''функция собирает новости по ключевым словам с ресурса harb.ru'''\n",
    "    '''на вход подается список ключевых слов'''\n",
    "    '''на выходе формируется датафрейм с иформацией'''\n",
    "    news = pd.DataFrame()\n",
    "    req = requests.get('https://habr.com/ru/all')\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "    posts = soup.find_all('article', class_='post')\n",
    "    news = pd.DataFrame()\n",
    "    for post in posts:\n",
    "        next_link = post.find('a', class_='post__title_link').get('href')\n",
    "        ref = requests.get(next_link)\n",
    "        ref_soup = BeautifulSoup(ref.text, 'html.parser')\n",
    "        date = pd.to_datetime(ref_soup.find('span', class_ = 'post__time').get('data-time_published'), format='%Y%m%d %H:%M') \n",
    "        title = ref_soup.title.text\n",
    "        body = ref_soup.find('div', class_ ='post__text').text.strip()\n",
    "        for key in keys:\n",
    "            if key in title.lower() or key in body.lower():\n",
    "                bloc = {'дата': date, 'заголовок': title, 'ссылка': next_link, 'текст': body}\n",
    "                news = pd.concat([news, pd.DataFrame([bloc])])\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>дата</th>\n",
       "      <th>заголовок</th>\n",
       "      <th>ссылка</th>\n",
       "      <th>текст</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-01 15:36:00+00:00</td>\n",
       "      <td>Из ничего к ЦОД с VXLAN/EVPN или как готовить ...</td>\n",
       "      <td>https://habr.com/ru/post/526022/</td>\n",
       "      <td>В последние полгода удалось поработать над бол...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-01 13:30:00+00:00</td>\n",
       "      <td>FOSS News №40 – дайджест новостей и других мат...</td>\n",
       "      <td>https://habr.com/ru/post/526014/</td>\n",
       "      <td>Всем привет!\\n\\r\\nПродолжаем дайджесты новосте...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       дата  \\\n",
       "0 2020-11-01 15:36:00+00:00   \n",
       "0 2020-11-01 13:30:00+00:00   \n",
       "\n",
       "                                           заголовок  \\\n",
       "0  Из ничего к ЦОД с VXLAN/EVPN или как готовить ...   \n",
       "0  FOSS News №40 – дайджест новостей и других мат...   \n",
       "\n",
       "                             ссылка  \\\n",
       "0  https://habr.com/ru/post/526022/   \n",
       "0  https://habr.com/ru/post/526014/   \n",
       "\n",
       "                                               текст  \n",
       "0  В последние полгода удалось поработать над бол...  \n",
       "0  Всем привет!\\n\\r\\nПродолжаем дайджесты новосте...  "
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_in_harb_posts(KEYWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2.\n",
    "Обязательная часть\n",
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса Avast Hack Ckeck https://www.avast.com/hackcheck/. \n",
    "Список email-ов задаем переменной в начале кода:\n",
    "EMAIL = [xxx@x.ru, yyy@y.com]\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <почта> - <дата утечки> - <источник утечки> - <описание утечки>.\n",
    "\n",
    "Дополнительная часть (необязательная)\n",
    "Написать скрипт, который будет получать 50 последних постов указанной группы во Вконтакте.\n",
    "Документация к API VK: https://vk.com/dev/methods , вам поможет метод wall.getGROUP = 'netology'\n",
    "TOKEN = УДАЛЯЙТЕ В ВЕРСИИ ДЛЯ ПРОВЕРКИ, НА GITHUB НЕ ВЫКЛАДЫВАТЬ\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <дата поста> - <текст поста>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_leak_check(email):\n",
    "    '''Функция проверяет емэйл на утечку в сети через сервис Avast'''\n",
    "    '''на вход подается емэйл или список из емэйлов'''\n",
    "    '''на выходе формируется датафрейм с информацией об утечке'''\n",
    "    '''предварительно необходимо подгрузить библиотеки json и requests'''\n",
    "    if type(email) == list:\n",
    "        email_list = []\n",
    "        site_list = []\n",
    "        descript_list = []\n",
    "        data_list = []\n",
    "        for mail in email:    \n",
    "            json = { 'emailAddresses' :[mail]}\n",
    "            headers = {'Vaar-Header-App-Product': 'hackcheck-web-avast','Vaar-Version': '0'}\n",
    "            url = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'\n",
    "            avast = requests.post(url=url, json=json, headers=headers)\n",
    "            for key, value in avast.json().items():\n",
    "                for data, data_info in value.items():\n",
    "                    for title, info in data_info.items():\n",
    "                        if title == 'site':\n",
    "                            email_list.append(list(avast.json()['summary'].keys())[0])\n",
    "                            site_list.append(info)\n",
    "                        elif title == 'description':\n",
    "                            descript_list.append(info)\n",
    "                        elif title == 'publishDate':\n",
    "                            data_list.append(info) \n",
    "        leak_df = pd.DataFrame({'email': email_list, 'date': data_list, 'site': site_list, 'description': descript_list})\n",
    "        return leak_df\n",
    "    else:          \n",
    "        json = { 'emailAddresses' :[email]}\n",
    "        headers = {'Vaar-Header-App-Product': 'hackcheck-web-avast','Vaar-Version': '0'}\n",
    "        url = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'\n",
    "        avast = requests.post(url=url, json=json, headers=headers)\n",
    "        email_list = []\n",
    "        site_list = []\n",
    "        descript_list = []\n",
    "        data_list = []\n",
    "        for key, value in avast.json().items():\n",
    "                for data, data_info in value.items():\n",
    "                    for title, info in data_info.items():\n",
    "                        if title == 'site':\n",
    "                            email_list.append(list(avast.json()['summary'].keys())[0])\n",
    "                            site_list.append(info)\n",
    "                        elif title == 'description':\n",
    "                            descript_list.append(info)\n",
    "                        elif title == 'publishDate':\n",
    "                            data_list.append(info) \n",
    "        leak_df = pd.DataFrame({'email': email_list, 'date': data_list, 'site': site_list, 'description': descript_list})  \n",
    "        return leak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL = ['xxx@x.ru', 'yyy@y.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>date</th>\n",
       "      <th>site</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2017-02-14T00:00:00Z</td>\n",
       "      <td>parapa.mail.ru</td>\n",
       "      <td>In July and August 2016, two criminals execute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2016-10-29T00:00:00Z</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>Popular Russian social networking platform VKo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>adobe.com</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2017-02-14T00:00:00Z</td>\n",
       "      <td>cfire.mail.ru</td>\n",
       "      <td>In July and August of 2016, two criminals carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2017-01-31T00:00:00Z</td>\n",
       "      <td>cdprojektred.com</td>\n",
       "      <td>In March 2016, CDProjektRed.com.com's forum da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2016-10-23T00:00:00Z</td>\n",
       "      <td>imesh.com</td>\n",
       "      <td>In June 2016, a cache of over 51 million user ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2020-01-03T00:00:00Z</td>\n",
       "      <td>azcentral.com</td>\n",
       "      <td>At an unconfirmed date, online Arizona newspap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2020-05-28T00:00:00Z</td>\n",
       "      <td>wishbone.io</td>\n",
       "      <td>In January 2020, the online poll website Wishb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2017-11-04T00:00:00Z</td>\n",
       "      <td>myheritage.com</td>\n",
       "      <td>In October 2017, a customer database belonging...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2019-06-13T00:00:00Z</td>\n",
       "      <td>canva.com</td>\n",
       "      <td>In May 2019, graphic-design site Canva's datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2016-10-24T00:00:00Z</td>\n",
       "      <td>dropbox.com</td>\n",
       "      <td>Cloud storage company Dropbox suffered a major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>linkedin.com</td>\n",
       "      <td>In 2012, online professional networking platfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2017-03-01T00:00:00Z</td>\n",
       "      <td>rayli.com.cn</td>\n",
       "      <td>On an unconfirmed date, Chinese gossip site Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2019-10-17T00:00:00Z</td>\n",
       "      <td>zynga.com</td>\n",
       "      <td>In September 2019, the game developer Zynga wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>adobe.com</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2018-02-18T00:00:00Z</td>\n",
       "      <td>netlog.com</td>\n",
       "      <td>Netlog (formerly known as Facebox and Bingbox)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2017-03-15T00:00:00Z</td>\n",
       "      <td>globalreach.eu</td>\n",
       "      <td>In 2016, Global Reach Technology's database wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2016-10-23T00:00:00Z</td>\n",
       "      <td>imesh.com</td>\n",
       "      <td>In June 2016, a cache of over 51 million user ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2017-03-24T00:00:00Z</td>\n",
       "      <td>youku.com</td>\n",
       "      <td>Youku is a large Chinese video content company...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        email                  date              site  \\\n",
       "0    xxx@x.ru  2017-02-14T00:00:00Z    parapa.mail.ru   \n",
       "1    xxx@x.ru  2016-10-29T00:00:00Z            vk.com   \n",
       "2    xxx@x.ru  2016-10-21T00:00:00Z         adobe.com   \n",
       "3    xxx@x.ru  2017-02-14T00:00:00Z     cfire.mail.ru   \n",
       "4    xxx@x.ru  2017-01-31T00:00:00Z  cdprojektred.com   \n",
       "5    xxx@x.ru  2016-10-23T00:00:00Z         imesh.com   \n",
       "6   yyy@y.com  2020-01-03T00:00:00Z     azcentral.com   \n",
       "7   yyy@y.com  2020-05-28T00:00:00Z       wishbone.io   \n",
       "8   yyy@y.com  2017-11-04T00:00:00Z    myheritage.com   \n",
       "9   yyy@y.com  2019-06-13T00:00:00Z         canva.com   \n",
       "10  yyy@y.com  2016-10-24T00:00:00Z       dropbox.com   \n",
       "11  yyy@y.com  2016-10-21T00:00:00Z      linkedin.com   \n",
       "12  yyy@y.com  2017-03-01T00:00:00Z      rayli.com.cn   \n",
       "13  yyy@y.com  2019-10-17T00:00:00Z         zynga.com   \n",
       "14  yyy@y.com  2016-10-21T00:00:00Z         adobe.com   \n",
       "15  yyy@y.com  2018-02-18T00:00:00Z        netlog.com   \n",
       "16  yyy@y.com  2017-03-15T00:00:00Z    globalreach.eu   \n",
       "17  yyy@y.com  2016-10-23T00:00:00Z         imesh.com   \n",
       "18  yyy@y.com  2017-03-24T00:00:00Z         youku.com   \n",
       "\n",
       "                                          description  \n",
       "0   In July and August 2016, two criminals execute...  \n",
       "1   Popular Russian social networking platform VKo...  \n",
       "2   In October of 2013, criminals penetrated Adobe...  \n",
       "3   In July and August of 2016, two criminals carr...  \n",
       "4   In March 2016, CDProjektRed.com.com's forum da...  \n",
       "5   In June 2016, a cache of over 51 million user ...  \n",
       "6   At an unconfirmed date, online Arizona newspap...  \n",
       "7   In January 2020, the online poll website Wishb...  \n",
       "8   In October 2017, a customer database belonging...  \n",
       "9   In May 2019, graphic-design site Canva's datab...  \n",
       "10  Cloud storage company Dropbox suffered a major...  \n",
       "11  In 2012, online professional networking platfo...  \n",
       "12  On an unconfirmed date, Chinese gossip site Ra...  \n",
       "13  In September 2019, the game developer Zynga wa...  \n",
       "14  In October of 2013, criminals penetrated Adobe...  \n",
       "15  Netlog (formerly known as Facebox and Bingbox)...  \n",
       "16  In 2016, Global Reach Technology's database wa...  \n",
       "17  In June 2016, a cache of over 51 million user ...  \n",
       "18  Youku is a large Chinese video content company...  "
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_leak_check(EMAIL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
